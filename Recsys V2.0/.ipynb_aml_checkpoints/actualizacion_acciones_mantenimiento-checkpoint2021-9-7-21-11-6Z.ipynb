{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1633635782261
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.__version__"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 2,
          "data": {
            "text/plain": "'1.3.3'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1633635784613
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Procesamiento columna 'Descripción'"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "excel_file = pd.ExcelFile('Users/SVELASQUEZ/Recsys V2.0/data/raw/actualizacion_acciones_mantenimiento/data.xlsx', engine='openpyxl')\r\n",
        "sheets = excel_file.sheet_names\r\n",
        "sheets"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 9,
          "data": {
            "text/plain": "['Lista de equipos',\n 'Historico calif 2_1(10 años)',\n 'T-PAP(C)_T-ACE',\n 'ARC(I)_ARC(D)',\n 'DP',\n 'OIL.TAP',\n 'DIEL.PF_ DIEL',\n 'OIL.CORR',\n 'PRO-M',\n 'M.OLTC']"
          },
          "metadata": {}
        }
      ],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1633635971693
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import unidecode\r\n",
        "\r\n",
        "def norm_descrpcion(s):\r\n",
        "    s = s.lower()\r\n",
        "    s = unidecode.unidecode(s)\r\n",
        "    return s\r\n",
        "\r\n",
        "converter_descripcion = {}\r\n",
        "converter_descripcion['Descripción'] = norm_descrpcion\r\n",
        "\r\n",
        "df_collection = {}\r\n",
        "for name in sheets:\r\n",
        "    df_collection[name] = pd.read_excel('../data/raw/actualizacion_acciones_mantenimiento/data.xlsx', sheet_name=name, converters=converter_descripcion)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Separación manual"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def separacion_manual(dframe, originales, reemplazos, adiciones):\r\n",
        "    df = dframe.copy()\r\n",
        "    for i in range(len(originales)):\r\n",
        "        index = df['Descripción'] == originales[i]\r\n",
        "        if sum(index) > 0:\r\n",
        "            instancias = df.loc[index].copy()\r\n",
        "            df.loc[index,'Descripción'] = reemplazos[i]\r\n",
        "            df = df.append(instancias, ignore_index = True)\r\n",
        "            df.loc[len(df) - sum(index):,'Descripción'] = adiciones[i]\r\n",
        "    return df\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "df_collection_separados = {}\r\n",
        "\r\n",
        "excel_file_reemplazos = pd.ExcelFile('../data/raw/actualizacion_acciones_mantenimiento/reemplazos_manual.xlsx')\r\n",
        "sheets_reemplazos = excel_file_reemplazos.sheet_names\r\n",
        "df_collection_manuales = {}\r\n",
        "\r\n",
        "converter_manuales = {}\r\n",
        "converter_manuales['Originales'] = norm_descrpcion\r\n",
        "converter_manuales['Reemplazos'] = norm_descrpcion\r\n",
        "converter_manuales['Adiciones'] = norm_descrpcion\r\n",
        "\r\n",
        "for name in sheets_reemplazos:#sheets_reemplazos:\r\n",
        "    df_collection_manuales[name] = pd.read_excel('../data/raw/actualizacion_acciones_mantenimiento/reemplazos_manual.xlsx', sheet_name = name, converters = converter_manuales)\r\n",
        "    index_manuales = ~df_collection_manuales[name].loc[:,'Reemplazos'].isna()\r\n",
        "    originales = df_collection_manuales[name].loc[index_manuales, 'Originales'].values\r\n",
        "    reemplazos = df_collection_manuales[name].loc[index_manuales, 'Reemplazos'].values\r\n",
        "    adiciones = df_collection_manuales[name].loc[index_manuales, 'Adiciones'].values\r\n",
        "    df_collection_separados[name] = separacion_manual(df_collection[name], originales, reemplazos, adiciones)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Normalización por palabras clave"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "palabras_clave = {}\r\n",
        "palabras_clave['revisar/cambiar motoventilador'] = ['motoventilador','ventilador','motoventiladores','ventiladores']\r\n",
        "palabras_clave['realizar analisis dga y humedad seguimiento'] = ['dga']\r\n",
        "palabras_clave['hacer seguimiento generacion anormal de gases'] = ['generacion','energizacion','gases']\r\n",
        "palabras_clave['cambiar silica oltc'] = ['silica']\r\n",
        "palabras_clave['cambiar filtro oltc'] = ['filtro']\r\n",
        "palabras_clave['realizar secado oltc'] = ['secado']\r\n",
        "palabras_clave['realizar muestreo-analisis fsco-qco oltc'] = ['aceite','muestra','fsco','qco']\r\n",
        "palabras_clave['realizar regeneramiento aceite aislante'] = ['regeneramiento','regeneracion']\r\n",
        "palabras_clave['adicionar irgamet39 a 100ppm'] = ['irgamet','pasivador','pasivar']\r\n",
        "palabras_clave['temperatura devenado'] = ['calibrar indicador temperatura devanados']\r\n",
        "palabras_clave['efectuar prueba de descargas parciales'] = ['descargas parc']\r\n",
        "palabras_clave['seguimiento durante montaje'] = ['durante montaje']\r\n",
        "palabras_clave['verificar condicion antes energizar oltc'] = ['energizar']\r\n",
        "palabras_clave['realizar prueba estimacion humedad whrt'] = ['estimacion humedad']\r\n",
        "palabras_clave['cambiar valvula alivio presion'] = ['alivio presion', 'alivio de presion','valvula alivio','valvula de alivio','valvula de sobre presion','valvula sobre presion','valvula de sobrepresion','valvula sobrepresion']\r\n",
        "palabras_clave['presion subita'] = ['cambiar rele presion subita']\r\n",
        "palabras_clave['revisar/cambiar contador cambiador tapsbiador'] = ['contador']\r\n",
        "df_collection_pc = df_collection_separados.copy()\r\n",
        "unicos_pc = {}\r\n",
        "index_unicos_pc = {}\r\n",
        "\r\n",
        "for name in sheets_reemplazos:\r\n",
        "    unicos = pd.unique(df_collection_separados[name]['Descripción'])\r\n",
        "    index_unicos = np.zeros(len(unicos))\r\n",
        "    for i in range(len(unicos)):\r\n",
        "        index_unicos[i] = i\r\n",
        "        for key,value in palabras_clave.items():\r\n",
        "            for word in value:\r\n",
        "                if word in unicos[i]:\r\n",
        "                    df_collection_pc[name] = df_collection_pc[name].replace(unicos[i],key)\r\n",
        "                    unicos[i] = key\r\n",
        "                    break\r\n",
        "    unicos_pc[name] = unicos\r\n",
        "    index_unicos_pc[name] = index_unicos"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Aplicando algoritmo de distancia de Levenshtein"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Algoritmo de distancia de Levenshtein"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dist_lev(s1,s2):\r\n",
        "    dist_matrix = np.zeros((len(s1) + 1, len(s2) + 1))\r\n",
        "    dist_matrix[1:,0] = range(1,len(s1) + 1)\r\n",
        "    dist_matrix[0,1:] = range(1,len(s2) + 1)\r\n",
        "    for i in range(1, len(s1) + 1):\r\n",
        "        for j in range(1, len(s2) + 1):\r\n",
        "            if s1[i - 1] == s2[j - 1]:\r\n",
        "                dist_matrix[i,j] = min(dist_matrix[i - 1, j] + 1, \r\n",
        "                                    dist_matrix[i - 1, j - 1], \r\n",
        "                                    dist_matrix[i, j - 1] + 1)\r\n",
        "            else:\r\n",
        "                dist_matrix[i,j] = min(dist_matrix[i - 1, j] + 1, \r\n",
        "                                    dist_matrix[i - 1, j - 1] + 1, \r\n",
        "                                    dist_matrix[i, j - 1] + 1)\r\n",
        "    return dist_matrix[-1,-1]"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Aplicando y ordenando según distancia"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extrayendo valores únicos:\r\n",
        "ordenados_collection = {}\r\n",
        "dist_ordenados_collection = {}\r\n",
        "index_ordenados_collection = {}\r\n",
        "for name in sheets_reemplazos:\r\n",
        "    unicos = pd.unique(unicos_pc[name])\r\n",
        "    #Construyendo matriz de distancia de Levenshtein\r\n",
        "    dist_unicos = np.zeros((len(unicos), len(unicos)))\r\n",
        "    for i in range(len(unicos)):\r\n",
        "        for j in range(i + 1, len(unicos)):\r\n",
        "            dist_unicos[i, j] = dist_lev(unicos[i], unicos[j])\r\n",
        "            dist_unicos[j,i] = dist_unicos[i,j] \r\n",
        "    #Inizializar varibales\r\n",
        "    # dist_unicos = np.array([[0,8,8,10.5],[1,0,4,3],[2,5,0,6],[8,10,7,0]])\r\n",
        "    # unicos = [1,2,3,4]\r\n",
        "    ordenados = ['']*len(unicos)\r\n",
        "    dist_ordenados = np.zeros(len(unicos))\r\n",
        "    index_ordenados = np.zeros(len(unicos))\r\n",
        "    #Ubicando primer elemento\r\n",
        "    max_dist_index = np.argmax(dist_unicos)\r\n",
        "    max_dist_index = np.unravel_index(max_dist_index, np.shape(dist_unicos))\r\n",
        "    row = max_dist_index[0]\r\n",
        "    ordenados[0] = unicos[row]\r\n",
        "    index_ordenados[0] = row\r\n",
        "    dist_ordenados[0] = 0\r\n",
        "    dist_unicos[row,:] = np.inf\r\n",
        "    #Diagonal igual a infinito\r\n",
        "    for i in range(len(unicos)):\r\n",
        "        dist_unicos[i,i] = np.inf\r\n",
        "    #Ubicando el resto de los elementos\r\n",
        "    for i in range(len(unicos) - 1):\r\n",
        "        min_dist = np.min(dist_unicos[:,row])\r\n",
        "        dist_ordenados[i + 1] = dist_ordenados[i] + min_dist\r\n",
        "        row = np.argmin(dist_unicos[:,row])\r\n",
        "        ordenados[i + 1] = unicos[row]\r\n",
        "        index_ordenados[i + 1] = row\r\n",
        "        dist_unicos[row,:] = np.inf\r\n",
        "    #Ubicándolos por hoja\r\n",
        "    ordenados_collection[name] = ordenados\r\n",
        "    dist_ordenados_collection[name] = dist_ordenados\r\n",
        "    index_ordenados_collection[name] = index_ordenados"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Escribiendo los resultados en Excel"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xlsxwriter\r\n",
        "workbook = xlsxwriter.Workbook('../data/raw/actualizacion_acciones_mantenimiento/unicos_ordenados.xlsx')\r\n",
        "for name in sheets_reemplazos:\r\n",
        "    worksheet = workbook.add_worksheet(name)\r\n",
        "    for i in range(len(ordenados_collection[name])): \r\n",
        "        worksheet.write(i,0,ordenados_collection[name][i])\r\n",
        "        worksheet.write(i,1,ordenados_collection[name][i])\r\n",
        "        worksheet.write(i,2,dist_ordenados_collection[name][i])\r\n",
        "        worksheet.write(i,3,index_ordenados_collection[name][i])\r\n",
        "\r\n",
        "workbook.close()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Separación por equipos"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "equipos_unicos = pd.unique(df_collection['Lista de equipos']['Equipo'])\r\n",
        "df_collection_equipos = {}\r\n",
        "for sheet in sheets_reemplazos:\r\n",
        "    df_collection_equipos[sheet] = pd.DataFrame()\r\n",
        "    equipos_unicos = pd.unique(df_collection_pc[sheet]['Equipo'])\r\n",
        "    for equipo in equipos_unicos:\r\n",
        "        df_equipo = df_collection_pc[sheet].loc[df_collection_pc[sheet]['Equipo'] == equipo].copy()\r\n",
        "        descripciones_unicas = pd.unique(df_equipo['Descripción'])\r\n",
        "        equipo_descripcion = {'Equipo':[equipo]*len(descripciones_unicas),'Descripción':descripciones_unicas}\r\n",
        "        df_collection_equipos[sheet] = df_collection_equipos[sheet].append(pd.DataFrame(equipo_descripcion),ignore_index = True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.1",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "kernel_info": {
      "name": "python38-azureml"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}