{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "from pipline import Processing\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib"
      ],
      "outputs": [],
      "metadata": {
        "gather": {
          "logged": 1629991740918
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "df = pd.read_csv('data/raw/prueba_original.csv', delimiter=';')"
      ],
      "outputs": [],
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1629991909234
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "p = Processing()"
      ],
      "outputs": [],
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1629991913393
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "r = p.makebd(df)\n",
        "lis = np.load('utils/PeCat.npz')\n",
        "pc = lis['arr_0']"
      ],
      "outputs": [],
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1629991932881
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "r = p.standardized_texts(r, pc)"
      ],
      "outputs": [],
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1629991945208
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "pp = p.bd_principal(r)\n",
        "pp = p.standardized_columns(pp)\n",
        "bd, bd_t = p.creation_bds(pp, r)\n",
        "\n",
        "dga, oilp, oil_tap, oil_corr, insp, hump, hum_pap = bd\n",
        "for i in range(0,len(bd)):\n",
        "    base = bd[i]\n",
        "    base.to_csv('data/processed/' + bd_t[i] + '.csv', sep = ';', index = False)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/mnt/batch/tasks/shared/LS_root/mounts/clusters/general001/code/Users/SVELASQUEZ/Recsys V1.0/pipline.py:183: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  f_principales.OILP = f_principales.OILP.str.replace('DIE.PF', 'DIE')\n",
            "/mnt/batch/tasks/shared/LS_root/mounts/clusters/general001/code/Users/SVELASQUEZ/Recsys V1.0/pipline.py:184: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  f_principales.OILP = f_principales.OILP.str.replace('DIE.', 'DIE')\n",
            "/mnt/batch/tasks/shared/LS_root/mounts/clusters/general001/code/Users/SVELASQUEZ/Recsys V1.0/pipline.py:185: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  f_principales.OILP = f_principales.OILP.str.replace('8-SILI.GEL/8-ING.ANIM/8-RES.CALEF', '')\n",
            "/mnt/batch/tasks/shared/LS_root/mounts/clusters/general001/code/Users/SVELASQUEZ/Recsys V1.0/pipline.py:188: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  f_principales.BUJ = f_principales.BUJ.str.replace('/9-SILI.GEL/9-FUG.ACEI/9-FUN.TERM/9-NIV.ACEI/9-SIST.ENF', '')\n",
            "/mnt/batch/tasks/shared/LS_root/mounts/clusters/general001/code/Users/SVELASQUEZ/Recsys V1.0/pipline.py:189: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  f_principales.INSP = f_principales.INSP.str.replace('P.CUB', 'CUB')\n",
            "/mnt/batch/tasks/shared/LS_root/mounts/clusters/general001/code/Users/SVELASQUEZ/Recsys V1.0/pipline.py:280: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  oil_tap['OIL.TAP'] = oil_tap['OIL.TAP'].str.replace('-OIL.TAP', '')\n",
            "/mnt/batch/tasks/shared/LS_root/mounts/clusters/general001/code/Users/SVELASQUEZ/Recsys V1.0/pipline.py:288: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  oil_corr['OIL.CORR'] = oil_corr['OIL.CORR'].str.replace('-OIL.CORR', '')\n"
          ]
        }
      ],
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1629992062701
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "source": [
        "def test_preprocessing(df, secundarias, enc_perfil):\n",
        "    \n",
        "    copy = df\n",
        "    if 'FECHA' in copy.columns:\n",
        "        copy = copy.drop(columns=['FECHA'])\n",
        "\n",
        "    for column in secundarias:\n",
        "        ## checking_first\n",
        "        try:\n",
        "            if any(char.isdigit() for char in copy[copy[column].notna()][column].iloc[0]):\n",
        "\n",
        "                copy[column] = copy[column].apply(column_transf)\n",
        "\n",
        "            else:\n",
        "                copy[column] = copy[column].isnull()\n",
        "        \n",
        "        except IndexError:\n",
        "            copy[column] = False\n",
        "\n",
        "    \n",
        "    copy['perfil_catalogo'] = enc_perfil.transform(copy['perfil_catalogo'])\n",
        "\n",
        "    return copy\n",
        "\n",
        "\n",
        "\n",
        "def column_transf(x):\n",
        "    '''Get first element of string. It must be calification o secundary column.'''\n",
        "    if str(x)[0].isdigit():\n",
        "        return str(x)[0]\n",
        "    else: \n",
        "        return -1"
      ],
      "outputs": [],
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1629992104288
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "source": [
        "enc_perfil = joblib.load('utils/encoder_perfil.pkl')\n",
        "enc_avisos = joblib.load('utils/encoder_avisos.pkl')\n",
        "\n",
        "rf_hump = joblib.load('models/rf_hump.pkl')\n",
        "rf_humpap = joblib.load('models/rf_humpap.pkl')\n",
        "rf_dga = joblib.load('models/rf_dga.pkl')\n",
        "rf_insp = joblib.load('models/rf_insp.pkl')\n",
        "rf_oiltap = joblib.load('models/rf_oiltap.pkl')\n",
        "rf_oil = joblib.load('models/rf_oil.pkl')\n",
        "\n",
        "hump_sec = ['DIAG', 'DELTA', 'SILI.GEL','T_M','FUG.ACEI','ING.ANIM','FUN.TERM','RES.CALEF','NIV.ACEI','SIST.ENF']\n",
        "dga_sec = ['ARC','T.ACE','T.PAP','DP']\n",
        "humpap_sec = ['NO.EQ','DELTA','DIAG','WHRT']\n",
        "insp_sec = ['BUJ','ENF','M.OLTC','PRO-M','CUB','GAB','FUG.ACEI','COMP.ELEC','COMP.MEC','RES.CALEF']\n",
        "oil_sec = ['DIE','FQ']\n",
        "oiltap_sec = ['DIAG','DELTA-A','DELTA-B','DELTA-C']"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/anaconda/envs/azureml_py38/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator LabelEncoder from version 0.23.2 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  warnings.warn(\n",
            "/anaconda/envs/azureml_py38/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.23.2 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  warnings.warn(\n",
            "/anaconda/envs/azureml_py38/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.23.2 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1629992281237
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "source": [
        "test_humpap = pd.read_csv('data/processed/hum_pap.csv', delimiter=';')\n",
        "thumpap_filt = test_preprocessing(test_humpap, secundarias = humpap_sec, enc_perfil=enc_perfil)\n",
        "thumpap_filt = thumpap_filt.dropna(subset=['HUM_PAP'])\n",
        "thumpap_filt = thumpap_filt[thumpap_filt['HUM_PAP'] <= 3]\n",
        "ids = thumpap_filt['id_unique']\n",
        "thumpap_filt = thumpap_filt.drop(columns=['id_unique'])\n",
        "preds = rf_humpap.predict(thumpap_filt)\n",
        "preds = enc_avisos.inverse_transform(preds)\n",
        "humpap_preds = list(zip(preds, ids))\n",
        "humpap_preds = pd.DataFrame(humpap_preds, columns=['pred','id'])\n",
        "\n",
        "test_hump = pd.read_csv('data/processed/hump.csv', delimiter=';')\n",
        "thump_filt = test_preprocessing(test_hump, secundarias = hump_sec, enc_perfil=enc_perfil)\n",
        "thump_filt = thump_filt.dropna(subset=['HUMP'])\n",
        "thump_filt = thump_filt[thump_filt['HUMP'] <= 3]\n",
        "ids = thump_filt['id_unique']\n",
        "thump_filt = thump_filt.drop(columns=['id_unique'])\n",
        "preds = rf_hump.predict(thump_filt)\n",
        "preds = enc_avisos.inverse_transform(preds)\n",
        "hump_preds = list(zip(preds, ids))\n",
        "hump_preds = pd.DataFrame(hump_preds, columns=['pred','id'])\n",
        "\n",
        "test_dga = pd.read_csv('data/processed/dga.csv', delimiter=';')\n",
        "tdga_filt = test_preprocessing(test_dga, secundarias = dga_sec, enc_perfil=enc_perfil)\n",
        "tdga_filt = tdga_filt.dropna(subset=['DGA'])\n",
        "tdga_filt = tdga_filt[tdga_filt['DGA'] <= 3]\n",
        "ids = tdga_filt['id_unique']\n",
        "tdga_filt = tdga_filt.drop(columns=['id_unique'])\n",
        "preds = rf_dga.predict(tdga_filt)\n",
        "preds = enc_avisos.inverse_transform(preds)\n",
        "dga_preds = list(zip(preds, ids))\n",
        "dga_preds = pd.DataFrame(dga_preds, columns=['pred','id'])\n",
        "\n",
        "test_insp = pd.read_csv('data/processed/insp.csv', delimiter=';')\n",
        "tinsp_filt = test_preprocessing(test_insp, secundarias = insp_sec, enc_perfil=enc_perfil)\n",
        "tinsp_filt = tinsp_filt.dropna(subset=['INSP'])\n",
        "tinsp_filt = tinsp_filt[tinsp_filt['INSP'] <= 3]\n",
        "ids = tinsp_filt['id_unique']\n",
        "tinsp_filt = tinsp_filt.drop(columns=['id_unique'])\n",
        "preds = rf_insp.predict(tinsp_filt)\n",
        "preds = enc_avisos.inverse_transform(preds)\n",
        "insp_preds = list(zip(preds, ids))\n",
        "insp_preds = pd.DataFrame(insp_preds, columns=['pred','id'])\n",
        "\n",
        "test_oiltap = pd.read_csv('data/processed/oil_tap.csv', delimiter=';')\n",
        "toiltap_filt = test_preprocessing(test_oiltap, secundarias = oiltap_sec, enc_perfil=enc_perfil)\n",
        "toiltap_filt = toiltap_filt.dropna(subset=['OIL.TAP'])\n",
        "toiltap_filt = toiltap_filt[toiltap_filt['OIL.TAP'] <= 3]\n",
        "ids = toiltap_filt['id_unique']\n",
        "toiltap_filt = toiltap_filt.drop(columns=['id_unique'])\n",
        "preds = rf_oiltap.predict(toiltap_filt)\n",
        "preds = enc_avisos.inverse_transform(preds)\n",
        "oiltap_preds = list(zip(preds, ids))\n",
        "oiltap_preds = pd.DataFrame(insp_preds, columns=['pred','id'])\n",
        "\n",
        "test_oil = pd.read_csv('data/processed/oilp.csv', delimiter=';')\n",
        "toil_filt = test_preprocessing(test_oil, secundarias = oil_sec, enc_perfil=enc_perfil)\n",
        "toil_filt = toil_filt.dropna(subset=['OILP'])\n",
        "toil_filt = toil_filt[toil_filt['OILP'] <= 3]\n",
        "ids = toil_filt['id_unique']\n",
        "toil_filt = toil_filt.drop(columns=['id_unique'])\n",
        "preds = rf_oil.predict(toil_filt)\n",
        "preds = enc_avisos.inverse_transform(preds)\n",
        "oil_preds = list(zip(preds, ids))\n",
        "oil_preds = pd.DataFrame(oil_preds, columns=['pred','id'])"
      ],
      "outputs": [],
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1629992448480
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "source": [
        "pru = r\n",
        "preds = humpap_preds.append([dga_preds, insp_preds, oiltap_preds,hump_preds,oil_preds])\n",
        "\n",
        "ids = preds['id'].value_counts().index\n",
        "res = []\n",
        "for id in ids:\n",
        "    p = list(preds[preds['id'] == id]['pred'])\n",
        "    data = [id,p]\n",
        "    res.append(data)\n",
        "    \n",
        "recomendaciones = pd.DataFrame(res,columns=['id_unique','recomendaciones'])\n",
        "\n",
        "resultado = pru.set_index('id_unique').join(recomendaciones.set_index('id_unique')).reset_index()\n",
        "\n",
        "resultado = resultado.rename(columns={\"id_unique\": \"id\", \"Equipo\": \"equipo\",\"Posición medida\": \"posicion_medida\", \"Valor medido\": \"valor_medido\", \"Fecha\": \"fecha\", \"Equipo\": \"equipo\"})\n",
        "\n",
        "types = {'equipo': 'str', 'valor_medido':'str'}\n",
        "resultado = resultado.astype(types)\n",
        "\n",
        "resultado['recomendaciones'] = resultado['recomendaciones'].fillna('No Recomendaciones')\n",
        "\n",
        "resultado['recomendaciones'] = resultado['recomendaciones'].apply(lambda x: str(x).rstrip(']').lstrip('['))"
      ],
      "outputs": [],
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1629992478667
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "source": [
        "resultado.to_csv('data/recomendaciones/recs.csv')"
      ],
      "outputs": [],
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1629992760723
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "source": [
        "import pyodbc\n",
        "from sqlalchemy import create_engine\n",
        "from urllib.parse import quote_plus\n",
        "\n",
        "server = 'compartidos.database.windows.net'\n",
        "database = 'DB_SQL_RECSYS'\n",
        "username = 'sant_vel'\n",
        "password = 'Conexiones2030'   \n",
        "driver= '{ODBC Driver 17 for SQL Server}'\n",
        "\n",
        "cnxn = pyodbc.connect('DRIVER='+driver+';SERVER=tcp:'+server+';PORT=1433;DATABASE='+database+';UID='+username+';PWD='+ password)\n",
        "cursor = cnxn.cursor()\n",
        "#Truncate the table\n",
        "cursor.execute(\"TRUNCATE TABLE Recomendaciones;\")\n",
        "\n",
        "# Insert Dataframe into SQL Server:\n",
        "for index, row in resultado.iterrows():\n",
        "\n",
        "    cursor.execute(\"INSERT INTO Recomendaciones (id,equipo,posicion_medida,valor_medido,fecha,texto_fallas,perfil_catalogo, recomendaciones) values(?,?,?,?,?,?,?,?)\", row.id, row.equipo, row.posicion_medida, row.valor_medido, row.fecha, row.texto_fallas, row.perfil_catalogo, row.recomendaciones)\n",
        "cnxn.commit()\n",
        "cursor.close()"
      ],
      "outputs": [],
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.1 64-bit ('azureml_py38': conda)"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.1",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "interpreter": {
      "hash": "17c92ebe4c347de728263208104da506711e9388d419f2667b4726047bdcfa3c"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}